{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training-and-fine-tuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO0dPkcYb8hLC4zwKvF3z6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-case-studies/blob/master/huggingface-transformers-practice/training-and-fine-tuning/training_and_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jivRMocQdzfI"
      },
      "source": [
        "## Training and fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Pb8l0Si-dN"
      },
      "source": [
        "Model classes in ðŸ¤— Transformers are designed to be compatible with native PyTorch and TensorFlow 2 and can be used seamlessly with either. In this quickstart, we will show how to fine-tune (or train from scratch) a model using the standard training tools available in either framework. We will also show how to use our included `Trainer()` class which handles much of the complexity of training for you.\n",
        "\n",
        "Referemce: https://huggingface.co/transformers/training.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7PywmnSL_uC"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYm8-n_bMelQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import torch\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl-GcyGXMBJ9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z8AJjW2MDHx"
      },
      "source": [
        "from transformers import pipeline\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, Trainer, TrainingArguments\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "from pprint import pprint"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufsiNBKUM81e"
      },
      "source": [
        "## Fine-tuning in native PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r_dReC8M_Q8"
      },
      "source": [
        "Model classes in ðŸ¤— Transformers that don't begin with `TF` are [PyTorch Modules](https://pytorch.org/docs/master/generated/torch.nn.Module.html), meaning that you can use them just as you would any\n",
        "model in PyTorch for both inference and optimization.\n",
        "\n",
        "Let's consider the common task of fine-tuning a masked language model like BERT on a sequence classification dataset.\n",
        "When we instantiate a model with `PreTrainedModel.from_pretrained`, the model configuration and\n",
        "pre-trained weights of the specified model are used to initialize the model. The library also includes a number of\n",
        "task-specific final layers or 'heads' whose weights are instantiated randomly when not present in the specified\n",
        "pre-trained model. For example, instantiating a model with\n",
        "`BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)` will create a BERT model instance\n",
        "with encoder weights copied from the `bert-base-uncased` model and a randomly initialized sequence classification\n",
        "head on top of the encoder with an output size of 2. Models are initialized in `eval` mode by default. We can call\n",
        "`model.train()` to put it in train mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IYOeyNWNEHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0924febf-6d29-4ccd-8f70-cba46822675a"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "model.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCsE78jwh5yl"
      },
      "source": [
        "This is useful because it allows us to make use of the pre-trained BERT encoder and easily train it on whatever sequence classification dataset we choose. We can use any PyTorch optimizer, but our library also provides the `AdamW()` optimizer which implements gradient bias correction as well as weight decay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppLY_BcxRpfb"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3RrBz2TS_Nm"
      },
      "source": [
        "The optimizer allows us to apply different hyperpameters for specific parameter groups. \n",
        "\n",
        "For example, we can apply weight decay to all parameters other than bias and layer normalization terms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j24a3e78mFkO"
      },
      "source": [
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "   {\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
        "   {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}                             \n",
        "]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jBMJdjlInT7"
      },
      "source": [
        "Now we can set up a simple dummy training batch using `PreTrainedTokenizer.__call__`. This returns a `BatchEncoding` instance which prepares everything we might need to pass to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br1SGP40IpVt"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPvzzpFkI9qA",
        "outputId": "6f7b53fb-bd3a-480e-bbf7-2b502b62564b"
      },
      "source": [
        "text_batch = [\"I love Pixar.\", \"I don't care for Pixar.\"]\n",
        "encoding = tokenizer(text_batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "input_ids = encoding[\"input_ids\"]\n",
        "attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "print(input_ids)\n",
        "print(attention_mask)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  1045,  2293, 14255, 18684,  2099,  1012,   102,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  1045,  2123,  1005,  1056,  2729,  2005, 14255, 18684,  2099,\n",
            "          1012,   102]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3i-SmsrJFsT"
      },
      "source": [
        "When we call a classification model with the `labels` argument, the first returned element is the Cross Entropy loss\n",
        "between the predictions and the passed labels. Having already set up our optimizer, we can then do a backwards pass and\n",
        "update the weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjqQDi6vJGSt"
      },
      "source": [
        "labels = torch.tensor([1, 0]).unsqueeze(0)\n",
        "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "loss = outputs.loss\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SzxC9ncJfF4"
      },
      "source": [
        "Alternatively, you can just get the logits and calculate the loss yourself. The following is equivalent to the previous example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4nmOWfCJ0Pp"
      },
      "source": [
        "labels = torch.tensor([1, 0])\n",
        "outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "loss = F.cross_entropy(outputs.logits, labels)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCsoehdursv9"
      },
      "source": [
        "Of course, you can train on GPU by calling `to('cuda')` on the model and inputs as usual.\n",
        "\n",
        "We also provide a few learning rate scheduling tools. With the following, we can set up a scheduler which warms up for\n",
        "`num_warmup_steps` and then linearly decays to 0 by the end of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al80JaimKQZA"
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=10, num_training_steps=10)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuSrdXbTKY9c"
      },
      "source": [
        "Then all we have to do is call `scheduler.step()` after `optimizer.step()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmJVnj_Gsygv"
      },
      "source": [
        "loss.backward(retain_graph=True)\n",
        "optimizer.step()\n",
        "scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjWArtiKtUJ9"
      },
      "source": [
        "We highly recommend using `Trainer`, discussed below, which conveniently handles the moving parts of training ðŸ¤— Transformers models with features like mixed precision and easy tensorboard logging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWSj5vU5tdM6"
      },
      "source": [
        "### Freezing the encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3nPwPtStduZ"
      },
      "source": [
        "In some cases, you might be interested in keeping the weights of the pre-trained encoder frozen and optimizing only the\n",
        "weights of the head layers. To do so, simply set the `requires_grad` attribute to `False` on the encoder\n",
        "parameters, which can be accessed with the `base_model` submodule on any task-specific model in the library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-8ITr9tgHK"
      },
      "source": [
        "for param in model.base_model.parameters():\n",
        "  param.requires_grad = True"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-tdLBZCCveP"
      },
      "source": [
        "## Fine-tuning in native TensorFlow 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6t1PyXn0ONL"
      },
      "source": [
        "Sometimes you need to feed a pair of sentences to your model. For instance, if you want to classify if two sentences in a pair are similar, or for question-answering models, which take a context and a question. For BERT models, the input is then represented like this: \n",
        "\n",
        "```\n",
        "[CLS] Sequence A [SEP] Sequence B [SEP]\n",
        "```\n",
        "\n",
        "You can encode a pair of sentences in the format expected by your model by supplying the two sentences as two arguments (not a list since a list of two sentences will be interpreted as a batch of two single sentences, as we saw before). This will once again return a dict string to list of ints:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO5_CIA2Rv31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3cdd783-dbe2-4d69-8f10-cfbc954b65e9"
      },
      "source": [
        "encoded_input = tokenizer(\"How old are you?\", \"I'm 6 years old\")\n",
        "print(encoded_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 1731, 1385, 1132, 1128, 136, 102, 146, 112, 182, 127, 1201, 1385, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2xnOcTt24pE"
      },
      "source": [
        "This shows us what the `token_type_ids` are for: they indicate to the model which part of the inputs correspond to the first sentence and which part corresponds to the second sentence. Note that `token_type_ids` are not required or handled by all models. By default, a tokenizer will only return the inputs that its associated model expects. You can force the return (or the non-return) of any of those special arguments by using `return_input_ids` or `return_token_type_ids`.\n",
        "\n",
        "If we decode the token ids we obtained, we will see that the special tokens have been properly added."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Km0Y33QSL2X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1d64575-dcb4-46c0-e5cb-0dd8b1ebc35f"
      },
      "source": [
        "tokenizer.decode(encoded_input[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS] How old are you? [SEP] I'm 6 years old [SEP]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1G7Chhl4SLr"
      },
      "source": [
        "If you have a list of pairs of sequences you want to process, you should feed them as two lists to your tokenizer: the list of first sentences and the list of second sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JVZC78UnIMW",
        "outputId": "d1e2cb23-0ecb-49c4-9f12-43bd6b052cf0"
      },
      "source": [
        "batch_sentences = [\n",
        "   \"Hello I'm a single sentence\",\n",
        "   \"And another sentence\",\n",
        "   \"And the very very last one\"                \n",
        "]\n",
        "\n",
        "batch_of_second_sentences = [\n",
        "   \"I'm a sentence that goes with the first sentence\",\n",
        "   \"And I should be encoded with the second sentence\",\n",
        "   \"And I go with the very last one\"                           \n",
        "]\n",
        "\n",
        "encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences)\n",
        "print(encoded_inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102, 146, 112, 182, 170, 5650, 1115, 2947, 1114, 1103, 1148, 5650, 102], [101, 1262, 1330, 5650, 102, 1262, 146, 1431, 1129, 12544, 1114, 1103, 1248, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102, 1262, 146, 1301, 1114, 1103, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mcmgChE5vQf"
      },
      "source": [
        "As we can see, it returns a dictionary where each value is a list of lists of ints.\n",
        "\n",
        "To double-check what is fed to the model, we can decode each list in `input_ids` one by one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mKLonm5b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec9f564-ef60-488d-a2b8-9934478fa026"
      },
      "source": [
        "for ids in encoded_inputs[\"input_ids\"]:\n",
        "  print(tokenizer.decode(ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Hello I'm a single sentence [SEP] I'm a sentence that goes with the first sentence [SEP]\n",
            "[CLS] And another sentence [SEP] And I should be encoded with the second sentence [SEP]\n",
            "[CLS] And the very very last one [SEP] And I go with the very last one [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzvV4NRY8NGR"
      },
      "source": [
        "Once again, you can automatically pad your inputs to the maximum sentence length in the batch, truncate to the maximum length the model can accept and return tensors directly with the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjgKPRHI74L9"
      },
      "source": [
        "batch = tokenizer(batch_sentences, batch_of_second_sentences, padding=True, truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1oiDVgf9C9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf9e4c6-f88a-4cb0-ea90-0e980453d840"
      },
      "source": [
        "print(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  8667,   146,   112,   182,   170,  1423,  5650,   102,   146,\n",
            "           112,   182,   170,  5650,  1115,  2947,  1114,  1103,  1148,  5650,\n",
            "           102],\n",
            "        [  101,  1262,  1330,  5650,   102,  1262,   146,  1431,  1129, 12544,\n",
            "          1114,  1103,  1248,  5650,   102,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  101,  1262,  1103,  1304,  1304,  1314,  1141,   102,  1262,   146,\n",
            "          1301,  1114,  1103,  1304,  1314,  1141,   102,     0,     0,     0,\n",
            "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0DkcmGY9f_s"
      },
      "source": [
        "## Pre-tokenized inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0P5UQ339g-o"
      },
      "source": [
        "The tokenizer also accept pre-tokenized inputs. This is particularly useful when you want to compute labels and extract predictions in named entity recognition (NER) or part-of-speech tagging (POS tagging).\n",
        "\n",
        ">**Note**: Pre-tokenized does not mean your inputs are already tokenized (you wouldnâ€™t need to pass them through the tokenizer if that was the case) but just split into words (which is often the first step in subword tokenization algorithms like BPE).\n",
        "\n",
        "If you want to use pre-tokenized inputs, just set `is_split_into_words=True` when passing your inputs to the tokenizer. For instance, we have:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl-02GwO9XMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d12ecaf-c81c-46aa-f226-2a2e0c5ffd94"
      },
      "source": [
        "  encoded_input = tokenizer([\"Hello\", \"I'm\", \"a\", \"single\", \"sentence\"], is_split_into_words=True)\n",
        "  print(encoded_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 8667, 146, 112, 182, 170, 1423, 5650, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhCVFQRZ-Vgf"
      },
      "source": [
        "Note that the tokenizer still adds the ids of special tokens (if applicable) unless you pass `add_special_tokens=False`.\n",
        "\n",
        "This works exactly as before for batch of sentences or batch of pairs of sentences. You can encode a batch of sentences like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe6MTwj0-MZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8f37ee-c9ac-4c22-f028-b762e49666f9"
      },
      "source": [
        "batch_sentences = [\n",
        "  [\"Hello\", \"I'm\", \"a\", \"single\", \"sentence\"],\n",
        "  [\"And\", \"another\", \"sentence\"],\n",
        "  [\"And\", \"the\", \"very\", \"very\", \"last\", \"one\"]                \n",
        "]\n",
        "\n",
        "encoded_inputs = tokenizer(batch_sentences, is_split_into_words=True)\n",
        "print(encoded_inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102], [101, 1262, 1330, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgQn8UMK-zQN"
      },
      "source": [
        "or a batch of pair sentences like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV3CQyNX-vxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60ad933-d6f4-4555-d3a4-e9b16c340549"
      },
      "source": [
        "batch_of_second_sentences = [\n",
        "  [\"I'm\", \"a\", \"sentence\", \"that\", \"goes\", \"with\", \"the\", \"first\", \"sentence\"],\n",
        "  [\"And\", \"I\", \"should\", \"be\", \"encoded\", \"with\", \"the\", \"second\", \"sentence\"],\n",
        "  [\"And\", \"I\", \"go\", \"with\", \"the\", \"very\", \"last\", \"one\"]              \n",
        "]\n",
        "\n",
        "encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences, is_split_into_words=True)\n",
        "print(encoded_inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102, 146, 112, 182, 170, 5650, 1115, 2947, 1114, 1103, 1148, 5650, 102], [101, 1262, 1330, 5650, 102, 1262, 146, 1431, 1129, 12544, 1114, 1103, 1248, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102, 1262, 146, 1301, 1114, 1103, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8Q1ebZQ_ShJ"
      },
      "source": [
        "And you can add padding, truncation as well as directly return tensors like before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viM6Vcd6_Oio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d70e579-fc24-416c-dee3-80ff86c80ebd"
      },
      "source": [
        "batch = tokenizer(batch_sentences, batch_of_second_sentences, is_split_into_words=True, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  8667,   146,   112,   182,   170,  1423,  5650,   102,   146,\n",
            "           112,   182,   170,  5650,  1115,  2947,  1114,  1103,  1148,  5650,\n",
            "           102],\n",
            "        [  101,  1262,  1330,  5650,   102,  1262,   146,  1431,  1129, 12544,\n",
            "          1114,  1103,  1248,  5650,   102,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  101,  1262,  1103,  1304,  1304,  1314,  1141,   102,  1262,   146,\n",
            "          1301,  1114,  1103,  1304,  1314,  1141,   102,     0,     0,     0,\n",
            "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdTK9ZRh_eqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20320fe-8d11-474c-c82b-f02d0bc6ef48"
      },
      "source": [
        "batch = tokenizer(batch_sentences, batch_of_second_sentences, is_split_into_words=True, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(3, 21), dtype=int32, numpy=\n",
            "array([[  101,  8667,   146,   112,   182,   170,  1423,  5650,   102,\n",
            "          146,   112,   182,   170,  5650,  1115,  2947,  1114,  1103,\n",
            "         1148,  5650,   102],\n",
            "       [  101,  1262,  1330,  5650,   102,  1262,   146,  1431,  1129,\n",
            "        12544,  1114,  1103,  1248,  5650,   102,     0,     0,     0,\n",
            "            0,     0,     0],\n",
            "       [  101,  1262,  1103,  1304,  1304,  1314,  1141,   102,  1262,\n",
            "          146,  1301,  1114,  1103,  1304,  1314,  1141,   102,     0,\n",
            "            0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(3, 21), dtype=int32, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]],\n",
            "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3, 21), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]],\n",
            "      dtype=int32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}